{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3473cbd0-5de8-41c4-9057-fe15d3c796b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,classification_report\n",
    "import gensim.downloader as api\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03e6f6-db61-4f18-ae79-017e350170d0",
   "metadata": {},
   "source": [
    "# Read preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de043bef-638d-4f90-b864-e6786cf82512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer ha mentioned watching 1 oz episod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thought wa wonderful way spend time hot summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>thought movie right good job wa creative origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>going disagree previous comment side maltin on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>one expects star trek movie high art fan expec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                  lemmatized_review\n",
       "0              1  one reviewer ha mentioned watching 1 oz episod...\n",
       "1              1  wonderful little production filming technique ...\n",
       "2              1  thought wa wonderful way spend time hot summer...\n",
       "3              0  basically family little boy jake think zombie ...\n",
       "4              1  petter mattei love time money visually stunnin...\n",
       "...          ...                                                ...\n",
       "49995          1  thought movie right good job wa creative origi...\n",
       "49996          0  bad plot bad dialogue bad acting idiotic direc...\n",
       "49997          0  catholic taught parochial elementary school nu...\n",
       "49998          0  going disagree previous comment side maltin on...\n",
       "49999          0  one expects star trek movie high art fan expec...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_imdb_preprocessed.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de05dc5-a6b0-4d54-9a31-492d311a44a5",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e849868c-e078-44a2-8855-af5b5be95bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_review'], df['sentiment'], test_size=0.2, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beeb86e-0905-46ce-9339-b2a6b371a27e",
   "metadata": {},
   "source": [
    "# Load model Work2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5d2666-25a9-43ce-90df-2142691f7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbad24e-4319-4750-965f-8b1ee1c85778",
   "metadata": {},
   "source": [
    "# Create Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5df29a-0c75-4f11-b1e8-1dd562abd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "max_length = 100\n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=max_length)\n",
    "X_val_seq = pad_sequences(X_val_seq, maxlen=max_length)\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=max_length)\n",
    "\n",
    "\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model:\n",
    "        embedding_matrix[i] = w2v_model[word]\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0c057-032c-44f0-b08f-a1d54a961dd1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89a03ea-b784-44b7-af61-11ed6b89b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 300)          23351400  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 200)         80200     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 200)              60200     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,492,001\n",
      "Trainable params: 140,601\n",
      "Non-trainable params: 23,351,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1063/1063 [==============================] - 267s 250ms/step - loss: 0.5232 - accuracy: 0.7434 - val_loss: 0.7011 - val_accuracy: 0.4978\n",
      "Epoch 2/10\n",
      "1063/1063 [==============================] - 268s 252ms/step - loss: 0.6412 - accuracy: 0.6306 - val_loss: 0.5769 - val_accuracy: 0.7058\n",
      "Epoch 3/10\n",
      "1063/1063 [==============================] - 270s 254ms/step - loss: 0.6133 - accuracy: 0.6699 - val_loss: 0.6094 - val_accuracy: 0.6742\n",
      "Epoch 4/10\n",
      "1063/1063 [==============================] - 265s 249ms/step - loss: 0.5977 - accuracy: 0.6804 - val_loss: 0.5986 - val_accuracy: 0.6882\n",
      "Epoch 5/10\n",
      "1063/1063 [==============================] - 262s 246ms/step - loss: 0.5953 - accuracy: 0.6837 - val_loss: 0.5475 - val_accuracy: 0.7198\n",
      "Epoch 6/10\n",
      "1063/1063 [==============================] - 270s 254ms/step - loss: 0.5554 - accuracy: 0.7251 - val_loss: 0.4795 - val_accuracy: 0.7810\n",
      "Epoch 7/10\n",
      "1063/1063 [==============================] - 264s 249ms/step - loss: 0.5682 - accuracy: 0.7046 - val_loss: 0.6200 - val_accuracy: 0.6537\n",
      "Epoch 8/10\n",
      "1063/1063 [==============================] - 239s 224ms/step - loss: 0.5891 - accuracy: 0.6866 - val_loss: 0.6988 - val_accuracy: 0.6680\n",
      "Epoch 9/10\n",
      "1063/1063 [==============================] - 238s 224ms/step - loss: 0.5453 - accuracy: 0.7280 - val_loss: 0.5152 - val_accuracy: 0.7470\n",
      "Epoch 10/10\n",
      "1063/1063 [==============================] - 244s 229ms/step - loss: 0.5527 - accuracy: 0.7173 - val_loss: 0.5394 - val_accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a359a2b370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(SimpleRNN(100, return_sequences=True))) \n",
    "model.add(Bidirectional(SimpleRNN(100)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_seq, y_train, epochs=10, batch_size=32, validation_data=(X_val_seq, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dea38c-a95e-45f9-8e4a-9cbf07868a41",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ad74d8-9423-4c92-b892-8a7827c49fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 29ms/step\n",
      "Precision: 0.69\n",
      "Recall: 0.89\n",
      "F1 Score: 0.77\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.59      0.69      4961\n",
      "           1       0.69      0.89      0.77      5039\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.76      0.74      0.73     10000\n",
      "weighted avg       0.76      0.74      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_seq)\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead14e4-5445-441f-bce9-12abfa9622b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
