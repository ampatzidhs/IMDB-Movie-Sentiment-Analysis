{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961e4f3b-f9ab-4fe8-a1e4-4fec33f5381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anestis\\anaconda3\\envs\\Gpu_BackUp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, SimpleRNN, Dense,Flatten,Dropout,GRU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,classification_report\n",
    "import gensim.downloader as api\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification,DistilBertTokenizerFast\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm  \n",
    "import tensorflow as tf\n",
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3d2bec-2491-4869-a41d-35364d9e95a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer ha mentioned watching 1 oz episod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thought wa wonderful way spend time hot summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>thought movie right good job wa creative origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>going disagree previous comment side maltin on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>one expects star trek movie high art fan expec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                  lemmatized_review\n",
       "0              1  one reviewer ha mentioned watching 1 oz episod...\n",
       "1              1  wonderful little production filming technique ...\n",
       "2              1  thought wa wonderful way spend time hot summer...\n",
       "3              0  basically family little boy jake think zombie ...\n",
       "4              1  petter mattei love time money visually stunnin...\n",
       "...          ...                                                ...\n",
       "49995          1  thought movie right good job wa creative origi...\n",
       "49996          0  bad plot bad dialogue bad acting idiotic direc...\n",
       "49997          0  catholic taught parochial elementary school nu...\n",
       "49998          0  going disagree previous comment side maltin on...\n",
       "49999          0  one expects star trek movie high art fan expec...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset_imdb_preprocessed.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144ea58-74bc-40b6-8ad6-59961dd244f3",
   "metadata": {},
   "source": [
    "# Bert hugging face without fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32573a7-05b2-42e3-9a3e-f21e3a1aa4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Processing: 100%|██████████| 10000/10000 [59:39<00:00,  2.79review/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score στο test set: 0.7625\n",
      "Precision στο test set: 0.9109\n",
      "Recall στο test set: 0.6557\n",
      "Accuracy στο test set: 0.7942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset_imdb_preprocessed.csv\", index_col=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_review'], df['sentiment'], test_size=0.2, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=seed)\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\", \n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "    tokenizer=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "X_test_list = X_test.astype(str).tolist() \n",
    "\n",
    "predictions = []\n",
    "for text in tqdm(X_test_list, desc=\"Processing\", unit=\"review\"):\n",
    "    pred = classifier(text, truncation=True, padding=True)\n",
    "    predictions.append(pred[0]) \n",
    "\n",
    "\n",
    "y_pred = [1 if pred[\"label\"] == \"POSITIVE\" else 0 for pred in predictions]\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score στο test set: {f1:.4f}\")\n",
    "print(f\"Precision στο test set: {precision:.4f}\")\n",
    "print(f\"Recall στο test set: {recall:.4f}\")\n",
    "print(f\"Accuracy στο test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c6a0e-0a2e-45d8-8f1c-30aa5a13d421",
   "metadata": {},
   "source": [
    "# Bert hugging face with fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7c2e93-39e0-4087-97ad-affe64384ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 592,130\n",
      "Non-trainable params: 66,362,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "4250/4250 [==============================] - 534s 125ms/step - loss: 0.4873 - accuracy: 0.7687 - val_loss: 0.4181 - val_accuracy: 0.8125\n",
      "Epoch 2/5\n",
      "4250/4250 [==============================] - 532s 125ms/step - loss: 0.4356 - accuracy: 0.7964 - val_loss: 0.4159 - val_accuracy: 0.8118\n",
      "Epoch 3/5\n",
      "4250/4250 [==============================] - 532s 125ms/step - loss: 0.4307 - accuracy: 0.7996 - val_loss: 0.3942 - val_accuracy: 0.8192\n",
      "Epoch 4/5\n",
      "4250/4250 [==============================] - 539s 127ms/step - loss: 0.4249 - accuracy: 0.8034 - val_loss: 0.4113 - val_accuracy: 0.8088\n",
      "Epoch 5/5\n",
      "4250/4250 [==============================] - 546s 128ms/step - loss: 0.4218 - accuracy: 0.8044 - val_loss: 0.3880 - val_accuracy: 0.8268\n",
      "157/157 [==============================] - 113s 718ms/step\n",
      "Accuracy: 0.8183\n",
      "Recall: 0.7892\n",
      "Precision: 0.8404\n",
      "F1 Score: 0.8140\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset_imdb_preprocessed.csv\", index_col=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_review'], df['sentiment'], test_size=0.2, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "\n",
    "for layer in model.layers[:-3]:  \n",
    "    layer.trainable = False\n",
    "\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "\n",
    "train_labels = np.array(y_train.tolist())\n",
    "val_labels = np.array(y_val.tolist())\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings),val_labels))\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000).batch(8)\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      \n",
    "    patience=2,              \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping]  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_labels = np.array(y_test.tolist())\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),test_labels)).batch(64)\n",
    "\n",
    "\n",
    "predictions = model.predict(test_dataset)\n",
    "predicted_labels = np.argmax(predictions.logits, axis=-1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "recall = recall_score(test_labels, predicted_labels)\n",
    "precision = precision_score(test_labels, predicted_labels)\n",
    "f1 = f1_score(test_labels, predicted_labels)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
